{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__                           import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot                  as plt\n",
    "import numpy                              as np\n",
    "import random                             as rd\n",
    "import tables                             as tb\n",
    "import tensorflow                         as tf\n",
    "\n",
    "from glob                                 import glob\n",
    "from matplotlib.patches                   import Ellipse\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import keras.backend.tensorflow_backend   as   K\n",
    "\n",
    "from keras                                import regularizers\n",
    "from keras                                import callbacks\n",
    "\n",
    "from keras.models                         import Model, load_model\n",
    "\n",
    "from keras.layers                         import Input, Dense, MaxPooling3D, AveragePooling3D\n",
    "from keras.layers                         import Conv3D, Conv2D, AveragePooling2D, Activation, Dropout, ZeroPadding3D\n",
    "from keras.layers                         import Add\n",
    "from keras.layers                         import Flatten, BatchNormalization\n",
    "\n",
    "from keras.layers.normalization           import BatchNormalization\n",
    "from keras.layers.convolutional           import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core                    import Flatten\n",
    "\n",
    "from keras.optimizers                     import SGD, Adam, Nadam, Adadelta \n",
    "\n",
    "from keras.regularizers                   import l2, l1\n",
    "from keras.initializers                   import RandomNormal\n",
    "\n",
    "from keras.utils.layer_utils              import print_summary\n",
    "\n",
    "#for keras example MLP\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a combined file from several .npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npz_dir = \"/home/amenkara/PETALO_dnns/dnn/\"\n",
    "\n",
    "# input/output files\n",
    "\n",
    "files = glob(npz_dir + '*.npz')\n",
    "\n",
    "files = sorted(files)\n",
    "print(files)\n",
    "\n",
    "out_file = \"combined_file_15_january.npz\"\n",
    "\n",
    "X_    = []\n",
    "Compt_= []\n",
    "Ev_   = []\n",
    "\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    fn = np.load(f)\n",
    "    \n",
    "    if(len(X_) == 0):\n",
    "        X_     = fn['images']\n",
    "        Compt_ =  fn['labels']\n",
    "        Ev_    =  fn['event_number']\n",
    "    else:\n",
    "        X_     = np.concatenate((X_,     fn['images'])      )\n",
    "        Compt_ = np.concatenate((Compt_, fn['labels'])      ) \n",
    "        Ev_    = np.concatenate((Ev_,    fn['event_number']))\n",
    "    \n",
    "print(\"Saving combined file\")\n",
    "np.savez(out_file, X_=X_, Compt_=Compt_, Ev_=Ev_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"combined_file_15_january.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(out_file)\n",
    "X_, Compt_, Ev_ = data['X_'],data['Compt_'], data['Ev_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_compton_events_labels        =  []\n",
    "all_compton_events_images        =  []\n",
    "all_compton_events_id            =  []\n",
    "\n",
    "all_photoelectric_events_labels  =  []\n",
    "all_photoelectric_events_images  =  []\n",
    "all_photoelectric_events_id      =  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the events into photoelectric and Compton.\n",
    "\n",
    "for i,event in enumerate(Ev_):\n",
    "    if Compt_[i]== 0:\n",
    "        all_photoelectric_events_labels.append(Compt_[i])\n",
    "        all_photoelectric_events_images.append(X_[i])\n",
    "        all_photoelectric_events_id.append(event)\n",
    "    if Compt_[i]==1:\n",
    "        all_compton_events_labels.append(Compt_[i])\n",
    "        all_compton_events_images.append(X_[i])\n",
    "        all_compton_events_id.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then cut the longest in order it to be of the same lenght.\n",
    "cut_compton_events_labels =  all_compton_events_labels[: len(all_photoelectric_events_id)]\n",
    "cut_compton_events_images =  all_compton_events_images[: len(all_photoelectric_events_id)]\n",
    "cut_compton_events_id     =  all_compton_events_id[: len(all_photoelectric_events_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train     = []\n",
    "Compt_train = []\n",
    "Ev_train    = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list     = all_photoelectric_events_images + cut_compton_events_images\n",
    "Compt_train_list = all_photoelectric_events_labels + cut_compton_events_labels\n",
    "Ev_train_list    = all_photoelectric_events_id     + cut_compton_events_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_= np.array(X_train_list)\n",
    "Compt_= np.array(Compt_train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut = int(0.8*len(X_))\n",
    "val_cut   = int(0.9*len(X_))\n",
    "\n",
    "X_train      = X_[:train_cut]\n",
    "X_val        = X_[train_cut:val_cut] \n",
    "X_test       = X_[val_cut:]\n",
    "\n",
    "Compt_train  =  Compt_[:train_cut]\n",
    "Compt_val    =  Compt_[train_cut:val_cut]\n",
    "Compt_test   =  Compt_[val_cut:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CNN(inputs):\n",
    "    initial = \"random_uniform\"\n",
    "    #el 32 implica que hay 32 filtros de 5x5\n",
    "    cinputs = Conv2D(96, (5, 5), padding='same', strides=(2, 2), activation='relu', kernel_initializer=initial, kernel_regularizer=regularizers.l1(0.01),  activity_regularizer=regularizers.l1(0.01))(inputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', kernel_initializer=initial, kernel_regularizer=regularizers.l1(0.01),  activity_regularizer=regularizers.l1(0.01))(cinputs)\n",
    "    cinputs = Dropout(.2)(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    cinputs = Conv2D(384, (2, 2), padding='same', strides=(1, 1), activation='relu', kernel_initializer=initial, kernel_regularizer=regularizers.l1(0.01), activity_regularizer=regularizers.l1(0.01))(cinputs)\n",
    "    cinputs = Dropout(.2)(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    \n",
    "    f1 = Flatten()(cinputs)\n",
    "    f1 = Dense(units=64, activation='relu', kernel_initializer=initial)(f1)\n",
    "    #f1 = Dropout(.2)(f1)\n",
    "\n",
    "    inc_output = Dense(units=1, activation='sigmoid', kernel_initializer=initial)(f1)\n",
    "    \n",
    "    model = Model(inputs, inc_output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999,\n",
    "                                      epsilon=1e-08, schedule_decay=0.001), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(inputs):\n",
    "    cinputs = Conv2D(96, (5, 5))(inputs)\n",
    "    cinputs = Dense(32)(cinputs)\n",
    "    internal = Dense(32)(cinputs)\n",
    "    internal = Flatten()(internal)\n",
    "    output = Dense(1, activation='sigmoid')(internal)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Nadam(lr=0.0002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_VGG_like_convnet(inputs_):\n",
    "    model = Sequential()\n",
    "    # input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    cinputs = Conv2D(32, (3, 3), activation='relu')(inputs_)\n",
    "    cinputs = Conv2D(32, (3, 3), activation='relu')(cinputs)\n",
    "    cinputs = MaxPooling2D(pool_size=(2, 2))(cinputs)\n",
    "    cinputs = Dropout(0.25)\n",
    "\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    cinputs = Flatten(cinputs)\n",
    "    cinputs = Dense(256, activation='relu')(cinputs)\n",
    "    cinputs = Dropout(0.5)(cinputs)\n",
    "    cinputs = Dense(10, activation='softmax')(cinputs)\n",
    "    \n",
    "    f1 = Flatten()(cinputs)\n",
    "    inc_output = Dense(units=1, activation='sigmoid', kernel_initializer=initial)(cinputs)\n",
    "\n",
    "    model = Model(inputs, inc_output)\n",
    "    \n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dropout' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0a1bc5c65e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel_VGG_like_convnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-fcdd56b49214>\u001b[0m in \u001b[0;36mmodel_VGG_like_convnet\u001b[0;34m(inputs_)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#model.add(Dropout(0.25))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcinputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcinputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcinputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/IC-3.6-2018-08-29/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_format, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/IC-3.6-2018-08-29/lib/python3.6/site-packages/keras/backend/common.py\u001b[0m in \u001b[0;36mnormalize_data_format\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError('The `data_format` argument must be one of '\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dropout' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "dim     = 30\n",
    "\n",
    "input_  = Input((dim,dim,1))\n",
    "model   = model_VGG_like_convnet(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard = callbacks.TensorBoard(log_dir='./logs/Keras_VGG_lr_0_0001', histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Compt_train, batch_size=180, epochs=200, shuffle=True, callbacks=[tboard],verbose=1, validation_data=(X_val, Compt_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line from keras docu.\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_conv2d_16_january_last_layer_activation_is_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('model_conv2d_16_january.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test, batch_size=18, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cut is the accuracy. \n",
    "def plot_result(cut):\n",
    "elements = []\n",
    "for element in prediction:\n",
    "    if element > cut:\n",
    "        elements.append(0)\n",
    "    else:\n",
    "        elements.append(1)\n",
    "        \n",
    "    aciertos = 0\n",
    "    total = len(elements)\n",
    "    for i in range(total):\n",
    "        if elements[i]== Compt_test[i]:\n",
    "            aciertos += 1\n",
    "        \n",
    "    print(aciertos)    \n",
    "    return aciertos/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for i in range(500, 1000):\n",
    "    matrix.append([i/1000., plot_result(i/1000.)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.transpose(matrix)[0][:], np.transpose(matrix)[1][:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
