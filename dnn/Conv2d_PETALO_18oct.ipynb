{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__                           import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot                  as plt\n",
    "import numpy                              as np\n",
    "import random                             as rd\n",
    "import tables                             as tb\n",
    "import tensorflow                         as tf\n",
    "\n",
    "from glob                                 import glob\n",
    "from matplotlib.patches                   import Ellipse\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import keras.backend.tensorflow_backend   as   K\n",
    "\n",
    "from keras                                import regularizers\n",
    "from keras                                import callbacks\n",
    "\n",
    "from keras.models                         import Model, load_model\n",
    "\n",
    "from keras.layers                         import Input, Dense, MaxPooling3D, AveragePooling3D\n",
    "from keras.layers                         import Conv3D, Conv2D, AveragePooling2D, Activation, Dropout, ZeroPadding3D\n",
    "from keras.layers                         import Add\n",
    "from keras.layers                         import Flatten, BatchNormalization\n",
    "\n",
    "from keras.layers.normalization           import BatchNormalization\n",
    "from keras.layers.convolutional           import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core                    import Flatten\n",
    "\n",
    "from keras.optimizers                     import SGD, Adam, Nadam, Adadelta \n",
    "\n",
    "from keras.regularizers                   import l2, l1\n",
    "from keras.initializers                   import RandomNormal\n",
    "\n",
    "from keras.utils.layer_utils              import print_summary\n",
    "\n",
    "\n",
    "#os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a combined file from several .npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "npz_dir = \"/home/amenkara/petalo_files_26_nov/\"\n",
    "\n",
    "# input/output files\n",
    "\n",
    "files = glob(npz_dir + '*.npz')\n",
    "\n",
    "files = sorted(files)\n",
    "print(files)\n",
    "\n",
    "out_file = \"combined_file_26nov.npz\"\n",
    "\n",
    "X_    = []\n",
    "Compt_= []\n",
    "Var_  = []\n",
    "Mean_ = [] \n",
    "Ev_   = []\n",
    "\n",
    "\n",
    "for f in files:\n",
    "\n",
    "    fn = np.load(f)\n",
    "    \n",
    "    if(len(X_) == 0):\n",
    "        X_     = fn['X_train']\n",
    "        Compt_ =  fn['Compt_train']\n",
    "        Var_   =  fn['Varpos_train']\n",
    "        Mean_  =  fn['Meanpos_train']\n",
    "        Ev_    =  fn['Ev_train']\n",
    "    else:\n",
    "        X_     = np.concatenate((X_,     fn['X_train'])      )\n",
    "        Compt_ = np.concatenate((Compt_, fn['Compt_train'])  ) \n",
    "        Var_   = np.concatenate((Var_,   fn['Varpos_train']) )\n",
    "        Mean_  = np.concatenate((Mean_,  fn['Meanpos_train']))\n",
    "        Ev_    = np.concatenate((Ev_,    fn['Ev_train'])     )\n",
    "    \n",
    "print(\"Saving combined file\")\n",
    "\n",
    "np.savez(out_file,\n",
    "        X_=X_, Compt_= Compt_, Var_=Var_, Mean_=Mean_, Ev_=Ev_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"training_set_test.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(out_file)\n",
    "X_, Compt_, Ev_ = data['images'],data['labels'], data['event_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cut = int(0.8*len(X_))\n",
    "val_cut   = int(0.9*len(X_))\n",
    "\n",
    "X_train      = X_[:train_cut]\n",
    "X_val        = X_[train_cut:val_cut] \n",
    "X_test       = X_[val_cut:]\n",
    "\n",
    "Compt_train  =  Compt_[:train_cut]\n",
    "Compt_val    =  Compt_[train_cut:val_cut]\n",
    "Compt_test   =  Compt_[val_cut:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_CNN(inputs):\n",
    "    #el 32 implica que hay 32 filtros de 5x5\n",
    "    cinputs = Conv2D(96, (5, 5), padding='same', strides=(2, 2), activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1(0.01),  activity_regularizer=regularizers.l1(0.01))(inputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1(0.01),  activity_regularizer=regularizers.l1(0.01))(cinputs)\n",
    "    cinputs = Dropout(.2)(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    cinputs = Conv2D(384, (2, 2), padding='same', strides=(1, 1), activation='relu', kernel_initializer='he_normal', kernel_regularizer=regularizers.l1(0.01), activity_regularizer=regularizers.l1(0.01))(cinputs)\n",
    "    cinputs = Dropout(.2)(cinputs)\n",
    "    cinputs = BatchNormalization(epsilon=1e-05, axis=3, momentum=0.99, weights=None, beta_initializer='zero', gamma_initializer='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "    cinputs = AveragePooling2D(pool_size=(2, 2), data_format=None, padding=\"same\", strides=(2, 2))(cinputs)\n",
    "    \n",
    "    f1 = Flatten()(cinputs)\n",
    "    f1 = Dense(units=64, activation='relu', kernel_initializer='he_normal')(f1)\n",
    "    #f1 = Dropout(.2)(f1)\n",
    "\n",
    "    inc_output = Dense(units=1, activation='sigmoid', kernel_initializer='lecun_normal')(f1)\n",
    "    \n",
    "    model = Model(inputs, inc_output)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999,\n",
    "                                      epsilon=1e-08, schedule_decay=0.001), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim     = 30\n",
    "\n",
    "input_  = Input((dim,dim,1))\n",
    "model   = model_CNN(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 30, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 96)        2496      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 192)         166080    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 192)         768       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 384)         295296    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                98368     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 564,993\n",
      "Trainable params: 563,649\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tboard = callbacks.TensorBoard(log_dir='./logs/test_2', histogram_freq=0, write_graph=True, write_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 876 samples, validate on 109 samples\n",
      "Epoch 1/10\n",
      "876/876 [==============================] - 8s 10ms/step - loss: 709.1304 - acc: 0.5537 - val_loss: 548.3447 - val_acc: 0.4771\n",
      "Epoch 2/10\n",
      "876/876 [==============================] - 6s 7ms/step - loss: 513.4497 - acc: 0.6301 - val_loss: 437.1606 - val_acc: 0.6881\n",
      "Epoch 3/10\n",
      "876/876 [==============================] - 6s 7ms/step - loss: 430.0793 - acc: 0.6621 - val_loss: 374.7164 - val_acc: 0.6697\n",
      "Epoch 4/10\n",
      "876/876 [==============================] - 6s 6ms/step - loss: 369.1792 - acc: 0.6918 - val_loss: 325.6683 - val_acc: 0.6789\n",
      "Epoch 5/10\n",
      "876/876 [==============================] - 6s 6ms/step - loss: 318.0704 - acc: 0.6929 - val_loss: 285.8881 - val_acc: 0.6697\n",
      "Epoch 6/10\n",
      "876/876 [==============================] - 5s 6ms/step - loss: 276.0823 - acc: 0.6895 - val_loss: 254.8207 - val_acc: 0.6697\n",
      "Epoch 7/10\n",
      "876/876 [==============================] - 6s 6ms/step - loss: 245.4819 - acc: 0.6861 - val_loss: 231.5110 - val_acc: 0.6789\n",
      "Epoch 8/10\n",
      "876/876 [==============================] - 6s 6ms/step - loss: 224.3463 - acc: 0.6975 - val_loss: 215.3630 - val_acc: 0.6789\n",
      "Epoch 9/10\n",
      "876/876 [==============================] - 6s 7ms/step - loss: 209.7341 - acc: 0.6792 - val_loss: 205.1347 - val_acc: 0.6789\n",
      "Epoch 10/10\n",
      "876/876 [==============================] - 7s 8ms/step - loss: 199.5622 - acc: 0.6826 - val_loss: 198.2865 - val_acc: 0.6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea6d26e940>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Compt_train, batch_size=18, epochs=10, shuffle=False, callbacks=[tboard],verbose=1, validation_data=(X_val, Compt_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test, batch_size=18, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64670146]\n",
      " [0.67738295]\n",
      " [0.6780841 ]\n",
      " [0.6869407 ]\n",
      " [0.67786455]\n",
      " [0.677837  ]\n",
      " [0.7486085 ]\n",
      " [0.6778427 ]\n",
      " [0.6767174 ]\n",
      " [0.61790603]\n",
      " [0.67825085]\n",
      " [0.6778206 ]\n",
      " [0.67780066]\n",
      " [0.67780066]\n",
      " [0.6835331 ]\n",
      " [0.67612964]\n",
      " [0.6447569 ]\n",
      " [0.67751473]\n",
      " [0.6778408 ]\n",
      " [0.67788243]\n",
      " [0.6778227 ]\n",
      " [0.6786429 ]\n",
      " [0.56059176]\n",
      " [0.6702236 ]\n",
      " [0.68456787]\n",
      " [0.6782481 ]\n",
      " [0.6777771 ]\n",
      " [0.47137603]\n",
      " [0.67674243]\n",
      " [0.6777595 ]\n",
      " [0.67780066]\n",
      " [0.67755866]\n",
      " [0.67780066]\n",
      " [0.6777272 ]\n",
      " [0.67780066]\n",
      " [0.6769617 ]\n",
      " [0.709999  ]\n",
      " [0.646541  ]\n",
      " [0.67759967]\n",
      " [0.71087873]\n",
      " [0.67780066]\n",
      " [0.6777986 ]\n",
      " [0.673027  ]\n",
      " [0.48225918]\n",
      " [0.67797095]\n",
      " [0.67780066]\n",
      " [0.6801827 ]\n",
      " [0.67777264]\n",
      " [0.6799147 ]\n",
      " [0.6794535 ]\n",
      " [0.6960231 ]\n",
      " [0.67780066]\n",
      " [0.67050195]\n",
      " [0.6796907 ]\n",
      " [0.70458573]\n",
      " [0.67780066]\n",
      " [0.6777984 ]\n",
      " [0.6777956 ]\n",
      " [0.6637436 ]\n",
      " [0.67762786]\n",
      " [0.6957956 ]\n",
      " [0.6776073 ]\n",
      " [0.67780066]\n",
      " [0.6781926 ]\n",
      " [0.64862925]\n",
      " [0.67394435]\n",
      " [0.6800188 ]\n",
      " [0.67323494]\n",
      " [0.6745418 ]\n",
      " [0.67780066]\n",
      " [0.67552894]\n",
      " [0.67780066]\n",
      " [0.6784102 ]\n",
      " [0.6783563 ]\n",
      " [0.677798  ]\n",
      " [0.6241004 ]\n",
      " [0.6807137 ]\n",
      " [0.6763551 ]\n",
      " [0.6742781 ]\n",
      " [0.6656809 ]\n",
      " [0.6756416 ]\n",
      " [0.67744666]\n",
      " [0.674682  ]\n",
      " [0.6372402 ]\n",
      " [0.57682407]\n",
      " [0.6401756 ]\n",
      " [0.67780066]\n",
      " [0.67780066]\n",
      " [0.6777968 ]\n",
      " [0.67780066]\n",
      " [0.5820373 ]\n",
      " [0.6728148 ]\n",
      " [0.3579567 ]\n",
      " [0.7112013 ]\n",
      " [0.6656079 ]\n",
      " [0.512287  ]\n",
      " [0.722703  ]\n",
      " [0.6757584 ]\n",
      " [0.6815957 ]\n",
      " [0.6606137 ]\n",
      " [0.6779597 ]\n",
      " [0.59382576]\n",
      " [0.63087666]\n",
      " [0.67849076]\n",
      " [0.67579126]\n",
      " [0.67780596]\n",
      " [0.6770705 ]\n",
      " [0.589728  ]\n",
      " [0.6787439 ]\n",
      " [0.67670846]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(cut):\n",
    "    elements = []\n",
    "    for element in prediction:\n",
    "        if element > cut:\n",
    "            elements.append(0)\n",
    "        else:\n",
    "            elements.append(1)\n",
    "        \n",
    "    aciertos = 0\n",
    "    total = len(elements)\n",
    "    for i in range(total):\n",
    "        if elements[i]== Compt_test[i]:\n",
    "            aciertos += 1\n",
    "        \n",
    "    print(aciertos)    \n",
    "    return aciertos/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "40\n",
      "40\n",
      "41\n",
      "41\n",
      "43\n",
      "43\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "43\n",
      "43\n",
      "43\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "44\n",
      "46\n",
      "46\n",
      "47\n",
      "46\n",
      "49\n",
      "49\n",
      "49\n",
      "71\n",
      "72\n",
      "73\n",
      "76\n",
      "77\n",
      "77\n",
      "78\n",
      "79\n",
      "79\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "78\n",
      "79\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "81\n",
      "81\n",
      "81\n",
      "81\n",
      "81\n",
      "80\n",
      "79\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "matrix = []\n",
    "for i in range(500, 1000):\n",
    "    matrix.append([i/1000., plot_result(i/1000.)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3       , 0.3       , 0.30909091, 0.30909091, 0.30909091,\n",
       "       0.30909091, 0.30909091, 0.31818182, 0.32727273, 0.34545455,\n",
       "       0.33636364, 0.33636364, 0.32727273, 0.33636364, 0.35454545,\n",
       "       0.38181818, 0.38181818, 0.4       , 0.66363636, 0.70909091,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.71818182, 0.71818182,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273,\n",
       "       0.72727273, 0.72727273, 0.72727273, 0.72727273, 0.72727273])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fea6ea7d390>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.transpose(matrix)[0][:], np.transpose(matrix)[1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
